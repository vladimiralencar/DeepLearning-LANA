{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "minist.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMoEtGfGWNE8Tw9U12xng4O",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vladimiralencar/DeepLearning-LANA/blob/master/minist.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PtfMmR3i0Naf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "ef14c3c5-721b-4458-f4ba-359ea270b530"
      },
      "source": [
        "%%time\n",
        "'''Trains a simple convnet on the MNIST dataset.\n",
        "\n",
        "Gets to 99.25% test accuracy after 12 epochs\n",
        "(there is still a lot of margin for parameter tuning).\n",
        "16 seconds per epoch on a GRID K520 GPU.\n",
        "'''\n",
        "\n",
        "from __future__ import print_function\n",
        "import keras\n",
        "from keras.datasets import mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras import backend as K\n",
        "\n",
        "batch_size = 128\n",
        "num_classes = 10\n",
        "epochs = 60 # 30  # 12\n",
        "\n",
        "# input image dimensions\n",
        "img_rows, img_cols = 28, 28\n",
        "\n",
        "# the data, split between train and test sets\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "if K.image_data_format() == 'channels_first':\n",
        "    x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n",
        "    x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n",
        "    input_shape = (1, img_rows, img_cols)\n",
        "else:\n",
        "    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
        "    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
        "    input_shape = (img_rows, img_cols, 1)\n",
        "\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "x_train /= 255\n",
        "x_test /= 255\n",
        "print('x_train shape:', x_train.shape)\n",
        "print(x_train.shape[0], 'train samples')\n",
        "print(x_test.shape[0], 'test samples')\n",
        "\n",
        "# convert class vectors to binary class matrices\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, kernel_size=(3, 3),\n",
        "                 activation='relu',\n",
        "                 input_shape=input_shape))\n",
        "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "model.compile(loss=keras.losses.categorical_crossentropy,\n",
        "              optimizer=keras.optimizers.Adadelta(),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.fit(x_train, y_train,\n",
        "          batch_size=batch_size,\n",
        "          epochs=epochs,\n",
        "          verbose=1,\n",
        "          validation_data=(x_test, y_test))\n",
        "score = model.evaluate(x_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x_train shape: (60000, 28, 28, 1)\n",
            "60000 train samples\n",
            "10000 test samples\n",
            "Epoch 1/60\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 2.2735 - accuracy: 0.1537 - val_loss: 2.2315 - val_accuracy: 0.3590\n",
            "Epoch 2/60\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 2.2070 - accuracy: 0.2727 - val_loss: 2.1469 - val_accuracy: 0.5077\n",
            "Epoch 3/60\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 2.1196 - accuracy: 0.3633 - val_loss: 2.0395 - val_accuracy: 0.6230\n",
            "Epoch 4/60\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 2.0114 - accuracy: 0.4412 - val_loss: 1.9033 - val_accuracy: 0.6996\n",
            "Epoch 5/60\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 1.8736 - accuracy: 0.5102 - val_loss: 1.7387 - val_accuracy: 0.7397\n",
            "Epoch 6/60\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 1.7218 - accuracy: 0.5658 - val_loss: 1.5533 - val_accuracy: 0.7696\n",
            "Epoch 7/60\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 1.5615 - accuracy: 0.6068 - val_loss: 1.3617 - val_accuracy: 0.7899\n",
            "Epoch 8/60\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 1.4060 - accuracy: 0.6406 - val_loss: 1.1830 - val_accuracy: 0.8066\n",
            "Epoch 9/60\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 1.2677 - accuracy: 0.6654 - val_loss: 1.0302 - val_accuracy: 0.8189\n",
            "Epoch 10/60\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 1.1560 - accuracy: 0.6848 - val_loss: 0.9074 - val_accuracy: 0.8302\n",
            "Epoch 11/60\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 1.0625 - accuracy: 0.7002 - val_loss: 0.8117 - val_accuracy: 0.8372\n",
            "Epoch 12/60\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.9856 - accuracy: 0.7179 - val_loss: 0.7369 - val_accuracy: 0.8427\n",
            "Epoch 13/60\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.9311 - accuracy: 0.7261 - val_loss: 0.6781 - val_accuracy: 0.8498\n",
            "Epoch 14/60\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.8780 - accuracy: 0.7389 - val_loss: 0.6312 - val_accuracy: 0.8559\n",
            "Epoch 15/60\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.8367 - accuracy: 0.7496 - val_loss: 0.5930 - val_accuracy: 0.8611\n",
            "Epoch 16/60\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.8027 - accuracy: 0.7566 - val_loss: 0.5613 - val_accuracy: 0.8647\n",
            "Epoch 17/60\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.7704 - accuracy: 0.7666 - val_loss: 0.5339 - val_accuracy: 0.8686\n",
            "Epoch 18/60\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.7393 - accuracy: 0.7752 - val_loss: 0.5103 - val_accuracy: 0.8715\n",
            "Epoch 19/60\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.7161 - accuracy: 0.7818 - val_loss: 0.4909 - val_accuracy: 0.8750\n",
            "Epoch 20/60\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.6962 - accuracy: 0.7883 - val_loss: 0.4737 - val_accuracy: 0.8781\n",
            "Epoch 21/60\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.6772 - accuracy: 0.7940 - val_loss: 0.4584 - val_accuracy: 0.8806\n",
            "Epoch 22/60\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.6596 - accuracy: 0.8008 - val_loss: 0.4445 - val_accuracy: 0.8832\n",
            "Epoch 23/60\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.6421 - accuracy: 0.8035 - val_loss: 0.4318 - val_accuracy: 0.8856\n",
            "Epoch 24/60\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.6292 - accuracy: 0.8084 - val_loss: 0.4207 - val_accuracy: 0.8869\n",
            "Epoch 25/60\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.6147 - accuracy: 0.8142 - val_loss: 0.4103 - val_accuracy: 0.8898\n",
            "Epoch 26/60\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.6019 - accuracy: 0.8148 - val_loss: 0.4008 - val_accuracy: 0.8914\n",
            "Epoch 27/60\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.5885 - accuracy: 0.8206 - val_loss: 0.3923 - val_accuracy: 0.8932\n",
            "Epoch 28/60\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.5822 - accuracy: 0.8220 - val_loss: 0.3843 - val_accuracy: 0.8952\n",
            "Epoch 29/60\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.5712 - accuracy: 0.8267 - val_loss: 0.3771 - val_accuracy: 0.8968\n",
            "Epoch 30/60\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.5642 - accuracy: 0.8281 - val_loss: 0.3706 - val_accuracy: 0.8981\n",
            "Epoch 31/60\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.5520 - accuracy: 0.8313 - val_loss: 0.3641 - val_accuracy: 0.8990\n",
            "Epoch 32/60\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.5394 - accuracy: 0.8361 - val_loss: 0.3574 - val_accuracy: 0.9009\n",
            "Epoch 33/60\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.5361 - accuracy: 0.8371 - val_loss: 0.3519 - val_accuracy: 0.9025\n",
            "Epoch 34/60\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.5294 - accuracy: 0.8386 - val_loss: 0.3468 - val_accuracy: 0.9031\n",
            "Epoch 35/60\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.5209 - accuracy: 0.8427 - val_loss: 0.3418 - val_accuracy: 0.9047\n",
            "Epoch 36/60\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.5169 - accuracy: 0.8429 - val_loss: 0.3368 - val_accuracy: 0.9066\n",
            "Epoch 37/60\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.5108 - accuracy: 0.8446 - val_loss: 0.3323 - val_accuracy: 0.9072\n",
            "Epoch 38/60\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.5018 - accuracy: 0.8485 - val_loss: 0.3277 - val_accuracy: 0.9094\n",
            "Epoch 39/60\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.4948 - accuracy: 0.8509 - val_loss: 0.3236 - val_accuracy: 0.9104\n",
            "Epoch 40/60\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.4914 - accuracy: 0.8511 - val_loss: 0.3193 - val_accuracy: 0.9116\n",
            "Epoch 41/60\n",
            "469/469 [==============================] - 3s 5ms/step - loss: 0.4877 - accuracy: 0.8516 - val_loss: 0.3157 - val_accuracy: 0.9114\n",
            "Epoch 42/60\n",
            "469/469 [==============================] - 3s 5ms/step - loss: 0.4802 - accuracy: 0.8533 - val_loss: 0.3122 - val_accuracy: 0.9118\n",
            "Epoch 43/60\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.4753 - accuracy: 0.8563 - val_loss: 0.3090 - val_accuracy: 0.9125\n",
            "Epoch 44/60\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.4724 - accuracy: 0.8572 - val_loss: 0.3051 - val_accuracy: 0.9137\n",
            "Epoch 45/60\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.4646 - accuracy: 0.8595 - val_loss: 0.3017 - val_accuracy: 0.9153\n",
            "Epoch 46/60\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.4626 - accuracy: 0.8594 - val_loss: 0.2987 - val_accuracy: 0.9157\n",
            "Epoch 47/60\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.4600 - accuracy: 0.8614 - val_loss: 0.2958 - val_accuracy: 0.9167\n",
            "Epoch 48/60\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.4576 - accuracy: 0.8611 - val_loss: 0.2928 - val_accuracy: 0.9173\n",
            "Epoch 49/60\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.4507 - accuracy: 0.8645 - val_loss: 0.2898 - val_accuracy: 0.9171\n",
            "Epoch 50/60\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.4455 - accuracy: 0.8641 - val_loss: 0.2870 - val_accuracy: 0.9179\n",
            "Epoch 51/60\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.4400 - accuracy: 0.8671 - val_loss: 0.2846 - val_accuracy: 0.9180\n",
            "Epoch 52/60\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.4409 - accuracy: 0.8663 - val_loss: 0.2823 - val_accuracy: 0.9193\n",
            "Epoch 53/60\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.4346 - accuracy: 0.8687 - val_loss: 0.2798 - val_accuracy: 0.9191\n",
            "Epoch 54/60\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.4315 - accuracy: 0.8690 - val_loss: 0.2768 - val_accuracy: 0.9205\n",
            "Epoch 55/60\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.4307 - accuracy: 0.8683 - val_loss: 0.2744 - val_accuracy: 0.9203\n",
            "Epoch 56/60\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.4237 - accuracy: 0.8717 - val_loss: 0.2722 - val_accuracy: 0.9211\n",
            "Epoch 57/60\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.4209 - accuracy: 0.8724 - val_loss: 0.2700 - val_accuracy: 0.9219\n",
            "Epoch 58/60\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.4183 - accuracy: 0.8740 - val_loss: 0.2672 - val_accuracy: 0.9228\n",
            "Epoch 59/60\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.4196 - accuracy: 0.8738 - val_loss: 0.2657 - val_accuracy: 0.9223\n",
            "Epoch 60/60\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.4136 - accuracy: 0.8747 - val_loss: 0.2641 - val_accuracy: 0.9239\n",
            "Test loss: 0.2640978693962097\n",
            "Test accuracy: 0.9239000082015991\n",
            "CPU times: user 2min 27s, sys: 23.6 s, total: 2min 51s\n",
            "Wall time: 2min 22s\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}